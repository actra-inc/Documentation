"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[4474],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>u});var o=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=o.createContext({}),p=function(e){var t=o.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},d=function(e){var t=p(e.components);return o.createElement(l.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},c=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),c=p(n),u=r,m=c["".concat(l,".").concat(u)]||c[u]||h[u]||a;return n?o.createElement(m,i(i({ref:t},d),{},{components:n})):o.createElement(m,i({ref:t},d))}));function u(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,i=new Array(a);i[0]=c;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var p=2;p<a;p++)i[p]=n[p];return o.createElement.apply(null,i)}return o.createElement.apply(null,n)}c.displayName="MDXCreateElement"},29311:(e,t,n)=>{n.r(t),n.d(t,{frontMatter:()=>s,contentTitle:()=>l,metadata:()=>p,toc:()=>d,default:()=>c});var o=n(22122),r=n(19756),a=(n(67294),n(3905)),i=["components"],s={id:"EMGslideshow",title:"EMG-controlled Slideshow"},l=void 0,p={unversionedId:"Examples/EMGProjects/EMGslideshow",id:"Examples/EMGProjects/EMGslideshow",isDocsHomePage:!1,title:"EMG-controlled Slideshow",description:"In this tutorial, we will show you how to scroll through a presentation using your eyes. To do that, we will read EMG data from the muscles around your eyes and find the peaks which correspond to blinking, using them as a trigger to scroll to the next slide. Even though we are using eye blinks in this example, any EMG signals such as those produced by your jaw when you clench it or your arms when you move them can be used.",source:"@site/docs/Examples/EMGProjects/03-EMG_Controlled_Slideshow.md",sourceDirName:"Examples/EMGProjects",slug:"/Examples/EMGProjects/EMGslideshow",permalink:"/Documentation/Examples/EMGProjects/EMGslideshow",editUrl:"https://github.com/OpenBCI/Documentation/edit/master/websitev2/docs/Examples/EMGProjects/03-EMG_Controlled_Slideshow.md",version:"current",lastUpdatedBy:"Richard Waltman",lastUpdatedAt:1627405574,formattedLastUpdatedAt:"7/27/2021",sidebarPosition:3,frontMatter:{id:"EMGslideshow",title:"EMG-controlled Slideshow"},sidebar:"docs",previous:{title:"EMG controlled Music",permalink:"/Documentation/Examples/EMGProjects/EMGmusic"},next:{title:"EMG-controlled LED",permalink:"/Documentation/Examples/EMGProjects/EMG_LED"}},d=[{value:"Materials Required",id:"materials-required",children:[]},{value:"Step 1: Hardware Assembly",id:"step-1-hardware-assembly",children:[]},{value:"Step 2: Software Setup",id:"step-2-software-setup",children:[]},{value:"Step 4: Using a Python Script to Read the Data",id:"step-4-using-a-python-script-to-read-the-data",children:[]}],h={toc:d};function c(e){var t=e.components,n=(0,r.Z)(e,i);return(0,a.kt)("wrapper",(0,o.Z)({},h,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"In this tutorial, we will show you how to scroll through a presentation using your eyes. To do that, we will read EMG data from the muscles around your eyes and find the peaks which correspond to blinking, using them as a trigger to scroll to the next slide. Even though we are using eye blinks in this example, any EMG signals such as those produced by your jaw when you clench it or your arms when you move them can be used."),(0,a.kt)("p",null," Check out an example video of this tutorial being put into action!"),(0,a.kt)("p",null,"  ",(0,a.kt)("img",{parentName:"p",src:"https://media.giphy.com/media/ZdgAlXPlhKSMCYgKQU/giphy.gif",alt:"EMGslideshowgif"})),(0,a.kt)("p",null," The following instructions have been written for use with Windows 10."),(0,a.kt)("h2",{id:"materials-required"},"Materials Required"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"OpenBCI ",(0,a.kt)("a",{parentName:"li",href:"https://shop.openbci.com/collections/frontpage/products/cyton-biosensing-board-8-channel?variant=38958638542"},"Cyton Board")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("a",{parentName:"li",href:"https://shop.openbci.com/collections/frontpage/products/openbci-eeg-headband-kit"},"EEG Headband Kit")),(0,a.kt)("li",{parentName:"ol"},"Computer with downloaded OpenBCI ",(0,a.kt)("a",{parentName:"li",href:"/Documentation/Software/OpenBCISoftware/GUIDocs"},"GUI"))),(0,a.kt)("h2",{id:"step-1-hardware-assembly"},"Step 1: Hardware Assembly"),(0,a.kt)("p",null," Follow the ",(0,a.kt)("a",{parentName:"p",href:"https://docs.openbci.com/docs/AddOns/Headwear/HeadBand"},"tutorial")," to assemble the EEG Headband Kit, connect it to the Cyton Board, and read data from it using the OpenBCI GUI."),(0,a.kt)("p",null," ",(0,a.kt)("strong",{parentName:"p"},"Important"),": For this project, using a single channel is enough. When following the tutorials in the link above, you only need to connect the electrode on top of the eye you will be blinking (any eye if you will blink both) to Channel 1."),(0,a.kt)("h2",{id:"step-2-software-setup"},"Step 2: Software Setup"),(0,a.kt)("p",null," Download and install ",(0,a.kt)("a",{parentName:"p",href:"https://www.python.org/downloads/"},"Python")," (either version 2 or 3). Python might already be installed on your computer. Type python --version to check if you have Python version 2 or 3 installed. To use this program, you need the following Python packages installed:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"pylsl"),": use ",(0,a.kt)("inlineCode",{parentName:"p"},"python -m pip install pylsl")," from the Python folder in the command line to install it.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"pyautogui")," : use ",(0,a.kt)("inlineCode",{parentName:"p"},"python -m pip install pyautogui")," to install."),(0,a.kt)("h2",{parentName:"li",id:"step-3-stream-data-using-the-openbci-gui"},"Step 3: Stream data using the OpenBCI GUI"),(0,a.kt)("p",{parentName:"li"},"   Follow the networking ",(0,a.kt)("a",{parentName:"p",href:"https://docs.openbci.com/docs/Software/OpenBCISoftware/GUIWidgets#networking"},"tutorial")," on this link to learn how to stream data using LSL from the GUI. For this project, you will need to stream the EMG data from Channel 1 using the Networking Widget. Your Networking settings should look as follows:"),(0,a.kt)("img",{src:"https://github.com/OpenBCI/Documentation/blob/master/docs/assets/TutorialImages/EMG_Slideshow_GUI.png?raw=true",width:"70%"}),(0,a.kt)("p",{parentName:"li"},(0,a.kt)("strong",{parentName:"p"},"Important"),": Make sure your EMG widget is open before you start streaming."))),(0,a.kt)("h2",{id:"step-4-using-a-python-script-to-read-the-data"},"Step 4: Using a Python Script to Read the Data"),(0,a.kt)("p",null," The Python script will search for an EMG data stream. Once it finds the stream it will read it and detect any spikes that correspond to eye blinks. If an eye blink is detected and 2 seconds have passed since the last eye blink, it will press the space bar, which will make the presentation go to the next slide. The threshold for the time between blinks can be modified as needed to avoid debouncing."),(0,a.kt)("p",null," Get the Python script from ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/OpenBCI/OpenBCI_Tutorials/tree/master/EMG_Controlled_Slideshow"},"here")," by clicking on \u2018Raw\u2019 and copying it to a .py file in your Python folder. Once you\u2019re streaming data from the GUI, go to the Python folder from your command line by using the cd command, and run it using ",(0,a.kt)("inlineCode",{parentName:"p"},"python.exe <script_name>.py")),(0,a.kt)("p",null," Open your slideshow in Presentation mode. Every time you blink, it will go to the next slide. By modifying the time_thres and blink_thres parameters in the code you can adjust the time to wait between binks and the blink strength to your needs."),(0,a.kt)("p",null," Try it out and send us a video of your final prototype!"))}c.isMDXComponent=!0}}]);