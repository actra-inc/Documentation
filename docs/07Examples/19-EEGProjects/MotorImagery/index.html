<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Motor Imagery · OpenBCI Documentation</title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="This tutorial was made by Rakesh C Jakati."/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Motor Imagery · OpenBCI Documentation"/><meta property="og:type" content="website"/><meta property="og:url" content="https://openbci.github.io/"/><meta property="og:description" content="This tutorial was made by Rakesh C Jakati."/><meta property="og:image" content="https://openbci.github.io/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://openbci.github.io/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/img/favicon_large.ico"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-42419007-3"></script><script>
              window.dataLayer = window.dataLayer || [];
              function gtag(){dataLayer.push(arguments); }
              gtag('js', new Date());
              gtag('config', 'UA-42419007-3');
            </script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/favicon_large.ico" alt="OpenBCI Documentation"/><h2 class="headerTitleWithLogo">OpenBCI Documentation</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="https://openbci.com" target="_self">Main Site</a></li><li class=""><a href="https://shop.openbci.com" target="_self">Shop</a></li><li class=""><a href="https://openbci.com/forum/" target="_self">Forum</a></li><li class="siteNavGroupActive"><a href="/docs/Welcome" target="_self">Documentation</a></li><li class=""><a href="https://github.com/OpenBCI" target="_self">Github</a></li><li class=""><a href="/citations" target="_self">Citations</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search Docs" title="Search Docs"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>EEG Projects and Tutorials</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Welcome to OpenBCI<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/Welcome">Welcome to the OpenBCI Community</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Getting Started<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/01GettingStarted/GettingStartedLanding">Getting Started</a></li><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Boards</h4><ul><li class="navListItem"><a class="navItem" href="/docs/01GettingStarted/01-Boards/CytonGS">Cyton Getting Started Guide</a></li><li class="navListItem"><a class="navItem" href="/docs/01GettingStarted/01-Boards/DaisyGS">Daisy Getting Started Guide</a></li><li class="navListItem"><a class="navItem" href="/docs/01GettingStarted/01-Boards/GanglionGS">Ganglion Getting Started Guide</a></li><li class="navListItem"><a class="navItem" href="/docs/01GettingStarted/01-Boards/WiFiGS">WiFi Shield Getting Started Guide</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Biosensing Setups</h4><ul><li class="navListItem"><a class="navItem" href="/docs/01GettingStarted/02-Biosensing-Setups/EEGSetup">Setting up for EEG</a></li><li class="navListItem"><a class="navItem" href="/docs/01GettingStarted/02-Biosensing-Setups/ECGSetup">Setting up for ECG</a></li><li class="navListItem"><a class="navItem" href="/docs/01GettingStarted/02-Biosensing-Setups/EMGSetup">Setting up for EMG</a></li><li class="navListItem"><a class="navItem" href="/docs/01GettingStarted/02-Biosensing-Setups/ExGSetup">Setting up for EEG, EMG, and ECG at the same time</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Community</h4><ul><li class="navListItem"><a class="navItem" href="/docs/01GettingStarted/03-Community/Community">Welcome to the OpenBCI Community</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Cyton Board<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/02Cyton/CytonLanding">Cyton Board</a></li><li class="navListItem"><a class="navItem" href="/docs/02Cyton/CytonSpecs">Cyton Specs</a></li><li class="navListItem"><a class="navItem" href="/docs/02Cyton/CytonDataFormat">Cyton Data Format</a></li><li class="navListItem"><a class="navItem" href="/docs/02Cyton/CytonSDK">Cyton Board SDK</a></li><li class="navListItem"><a class="navItem" href="/docs/02Cyton/CytonProgram">Cyton Board Programming Tutorial</a></li><li class="navListItem"><a class="navItem" href="/docs/02Cyton/CytonRadios">Cyton Radios Programming Tutorial</a></li><li class="navListItem"><a class="navItem" href="/docs/02Cyton/CytonExternal">External Trigger on OpenBCI Cyton Board</a></li><li class="navListItem"><a class="navItem" href="/docs/02Cyton/CytonSDCard">Using SD Card with OpenBCI</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Ganglion Board<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/03Ganglion/GanglionLanding">Ganglion Board</a></li><li class="navListItem"><a class="navItem" href="/docs/03Ganglion/GanglionSpecs">Ganglion Specs</a></li><li class="navListItem"><a class="navItem" href="/docs/03Ganglion/GanglionDataFormat">Ganglion Data Format</a></li><li class="navListItem"><a class="navItem" href="/docs/03Ganglion/GanglionSDK">Ganglion SDK</a></li><li class="navListItem"><a class="navItem" href="/docs/03Ganglion/GanglionProgram">Ganglion Programming Tutorial</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Headwear &amp; Electrodes<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/04AddOns/AddOnLanding">Add Ons</a></li><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Headwear</h4><ul><li class="navListItem"><a class="navItem" href="/docs/04AddOns/01-Headwear/MarkIV">Ultracortex Mark IV</a></li><li class="navListItem"><a class="navItem" href="/docs/04AddOns/01-Headwear/MarkIII">Ultracortex Mark III</a></li><li class="navListItem"><a class="navItem" href="/docs/04AddOns/01-Headwear/HeadBand">OpenBCI EEG Headband Kit Guide</a></li><li class="navListItem"><a class="navItem" href="/docs/04AddOns/01-Headwear/ElectrodeCap">Electrode Cap Getting Started Guide</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Electrodes</h4><ul><li class="navListItem"><a class="navItem" href="/docs/04AddOns/02-Electrodes/ElectrodesLanding">Electrode Guide</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Third-Party Hardware<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/05ThirdParty/ThirdPartyLanding">Third-Party Hardware</a></li><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">EmotiBit</h4><ul><li class="navListItem"><a class="navItem" href="/docs/05ThirdParty/00-EmotiBit/EmotiBit_Guide">EmotiBit Guide</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">HEGduino Kit</h4><ul><li class="navListItem"><a class="navItem" href="/docs/05ThirdParty/05-HEGduino Kit/HEGduino">HEGduino How-to</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">IDUN Dryode</h4><ul><li class="navListItem"><a class="navItem" href="/docs/05ThirdParty/04-IDUN_Dryode/Dryode">IDUN Dryode™</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Myoware</h4><ul><li class="navListItem"><a class="navItem" href="/docs/05ThirdParty/01-Myoware/MyoCyton">MyoWare OpenBCI Integration (Cyton Board)</a></li><li class="navListItem"><a class="navItem" href="/docs/05ThirdParty/01-Myoware/MyoGanglion">MyoWare OpenBCI Integration (Ganglion Board)</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Pulse Sensor</h4><ul><li class="navListItem"><a class="navItem" href="/docs/05ThirdParty/02-Pulse_Sensor/Pulse_Sensor_Landing">Pulse Sensor Guide</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">ThinkPulse</h4><ul><li class="navListItem"><a class="navItem" href="/docs/05ThirdParty/06-ThinkPulse/ThinkPulse">ThinkPulse™ Getting Started Guide</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">WiFi Shield</h4><ul><li class="navListItem"><a class="navItem" href="/docs/05ThirdParty/03-WiFiShield/WiFiLanding">OpenBCI WiFi</a></li><li class="navListItem"><a class="navItem" href="/docs/05ThirdParty/03-WiFiShield/WiFiProgam">Wifi Shield Programming Tutorial</a></li><li class="navListItem"><a class="navItem" href="/docs/05ThirdParty/03-WiFiShield/WiFiAPI">OpenBCI WiFi Shield API</a></li><li class="navListItem"><a class="navItem" href="/docs/05ThirdParty/03-WiFiShield/WiFiSDK">OpenBCI Wifi SDK</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Software<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/06Software/SoftwareLanding">Compatible Software</a></li><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Developed By OpenBCI</h4><ul><li class="navListItem"><a class="navItem" href="/docs/06Software/01-OpenBCISoftware/GUIDocs">The OpenBCI GUI</a></li><li class="navListItem"><a class="navItem" href="/docs/06Software/01-OpenBCISoftware/GUIWidgets">GUI Widget Guide</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Compatible Third Party Software</h4><ul><li class="navListItem"><a class="navItem" href="/docs/06Software/02-CompatibleThirdPartySoftware/Matlab">MATLAB</a></li><li class="navListItem"><a class="navItem" href="/docs/06Software/02-CompatibleThirdPartySoftware/Neuromore">Neuromore</a></li><li class="navListItem"><a class="navItem" href="/docs/06Software/02-CompatibleThirdPartySoftware/OpenVibe">OpenViBE</a></li><li class="navListItem"><a class="navItem" href="/docs/06Software/02-CompatibleThirdPartySoftware/LSL">Lab Streaming Layer (LSL)</a></li><li class="navListItem"><a class="navItem" href="/docs/06Software/02-CompatibleThirdPartySoftware/BrainBay">BrainBay</a></li><li class="navListItem"><a class="navItem" href="/docs/06Software/02-CompatibleThirdPartySoftware/BioEra">BioEra</a></li><li class="navListItem"><a class="navItem" href="/docs/06Software/02-CompatibleThirdPartySoftware/VirtualBox">VirtualBox Windows Guide</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">For Developers<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/11ForDevelopers/ForDevelopersLanding">For Developers</a></li><li class="navListItem"><a class="navItem" href="/docs/11ForDevelopers/SoftwareDevelopment">Software Development</a></li><li class="navListItem"><a class="navItem" href="/docs/11ForDevelopers/FirmwareDevelopment">Firmware Development</a></li><li class="navListItem"><a class="navItem" href="/docs/11ForDevelopers/HardwareDevelopment">Hardware Development</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Deprecated Documents<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/09Deprecated/DeprecatedLanding">Deprecated Docs</a></li><li class="navListItem"><a class="navItem" href="/docs/09Deprecated/SpiderclawDep">Spiderclaw V1 &amp; V2 (deprecated)</a></li><li class="navListItem"><a class="navItem" href="/docs/09Deprecated/8bitBoardDep">OpenBCI 8bit Board (no longer in production)</a></li><li class="navListItem"><a class="navItem" href="/docs/09Deprecated/UltracortexMark1Dep">Ultracortex Mark 1</a></li><li class="navListItem"><a class="navItem" href="/docs/09Deprecated/UltracortexMark2Dep">Ultracortex Mark 2</a></li><li class="navListItem"><a class="navItem" href="/docs/09Deprecated/UltracortexMark3_NovaDep">Ultracortex Mark III &quot;Nova&quot; &amp; &quot;Supernova&quot; (REVISED)</a></li><li class="navListItem"><a class="navItem" href="/docs/09Deprecated/Python">Python and OpenBCI</a></li><li class="navListItem"><a class="navItem" href="/docs/09Deprecated/Hub">OpenBCI Hub</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Troubleshooting<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/10Troubleshooting/TroubleshootingLanding">Troubleshooting Landing</a></li><li class="navListItem"><a class="navItem" href="/docs/10Troubleshooting/minimizingNoise">Minimizing Noise</a></li><li class="navListItem"><a class="navItem" href="/docs/10Troubleshooting/GUI_Troubleshooting">GUI Troubleshooting</a></li><li class="navListItem"><a class="navItem" href="/docs/10Troubleshooting/FTDI_Fix_Linux">FTDI Buffer Fix on Linux</a></li><li class="navListItem"><a class="navItem" href="/docs/10Troubleshooting/FTDI_Fix_Mac">FTDI Buffer Fix on OS X</a></li><li class="navListItem"><a class="navItem" href="/docs/10Troubleshooting/FTDI_Fix_Windows">FTDI Buffer Fix on Windows</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">Example Projects<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><li class="navListItem"><a class="navItem" href="/docs/07Examples/ExamplesLanding">Example Projects</a></li><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Experiments</h4><ul><li class="navListItem"><a class="navItem" href="/docs/07Examples/VideoExperiment">Puppies and Kittens Experiment</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Community Page Projects</h4><ul><li class="navListItem"><a class="navItem" href="/docs/07Examples/CommunityPageProjects">Community Page Projects</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">EMG Projects and Tutorials</h4><ul><li class="navListItem"><a class="navItem" href="/docs/07Examples/18-EMGProjects/EMGscrolling">EMG Scrolling</a></li><li class="navListItem"><a class="navItem" href="/docs/07Examples/18-EMGProjects/EMGmusic">EMG-controlled Stop/Start Music</a></li><li class="navListItem"><a class="navItem" href="/docs/07Examples/18-EMGProjects/EMGslideshow">EMG-controlled Slideshow</a></li><li class="navListItem"><a class="navItem" href="/docs/07Examples/18-EMGProjects/EMG_LED">EMG-controlled LED</a></li><li class="navListItem"><a class="navItem" href="/docs/07Examples/18-EMGProjects/EMG_Chrome_Dino_Game">EMG Chrome Dino Game</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">EEG Projects and Tutorials</h4><ul><li class="navListItem"><a class="navItem" href="/docs/07Examples/19-EEGProjects/FocusArduino">Send Focus Data from GUI to Arduino</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/docs/07Examples/19-EEGProjects/MotorImagery">Motor Imagery</a></li></ul></div></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle collapsible">FAQ<span class="arrow"><svg width="24" height="24" viewBox="0 0 24 24"><path fill="#565656" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z"></path><path d="M0 0h24v24H0z" fill="none"></path></svg></span></h3><ul class="hide"><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">FAQ</h4><ul><li class="navListItem"><a class="navItem" href="/docs/08FAQ/FAQLanding">Frequently Asked Questions</a></li><li class="navListItem"><a class="navItem" href="/docs/08FAQ/GenFAQ">General Frequently Asked Questions</a></li><li class="navListItem"><a class="navItem" href="/docs/08FAQ/HowProductsGoTogether">How OpenBCI products go together?</a></li><li class="navListItem"><a class="navItem" href="/docs/08FAQ/HardFAQ">Hardware &amp; Software</a></li><li class="navListItem"><a class="navItem" href="/docs/08FAQ/PaymentFAQ">Purchases &amp; Payment Processing</a></li><li class="navListItem"><a class="navItem" href="/docs/08FAQ/ShippingFAQ">Shipping &amp; Taxes</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Policies</h4><ul><li class="navListItem"><a class="navItem" href="/docs/08FAQ/Cookie">OpenBCI Cookie Policy</a></li><li class="navListItem"><a class="navItem" href="/docs/08FAQ/Privacy">Privacy &amp; Security</a></li><li class="navListItem"><a class="navItem" href="/docs/08FAQ/Returns">RETURNS &amp; REFUNDS</a></li><li class="navListItem"><a class="navItem" href="/docs/08FAQ/Liability">Liability Policy</a></li></ul></div></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"><a class="edit-page-link button" href="https://github.com/OpenBCI/Documentation/edit/master/docs/07Examples/19-EEGProjects/20-Motor_Imagery.md" target="_blank" rel="noreferrer noopener">Edit</a><h1 id="__docusaurus" class="postHeaderTitle">Motor Imagery</h1></header><article><div><span><p>This tutorial was made by Rakesh C Jakati.</p>
<p>Motor imagery (MI)–based brain-computer interface (BCI) is one of the standard concepts of BCI, in that the user can generate induced activity from the motor cortex by imagining motor movements without any limb movement or external stimulus.
In this tutorial, we will learn how to use OpenBCI equipment for motor imagery. For that, we will design a BCI system that allows a user to control a system by imagining different movements of their limbs.</p>
<h2><a class="anchor" aria-hidden="true" id="materials-required"></a><a href="#materials-required" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Materials Required</h2>
<ol>
<li>OpenBCI <a href="https://shop.openbci.com/collections/frontpage/products/cyton-biosensing-board-8-channel?variant=38958638542">Cyton Board</a></li>
<li><a href="https://shop.openbci.com/collections/frontpage/products/ultracortex-mark-iv">Ultracortex EEG headset</a> or <a href="https://shop.openbci.com/collections/frontpage/products/openbci-eeg-electrocap-kit">EEG cap</a></li>
<li><a href="https://www.mouser.com/ProductDetail/Espressif-Systems/ESP32-DevKitC-32D?qs=%252BEew9%252B0nqrDsObWEpDx6YQ%3D%3D&amp;mgh=1&amp;gclid=Cj0KCQiAv6yCBhCLARIsABqJTjYSYNAq2huvV-lF7V7lKuONcge-Uw2UY4cy9z42E52fUWGZIaLCYzEaAoEyEALw_wcB">NodeMCU</a></li>
<li>NodeMCU constructed <a href="https://www.instructables.com/NodeMCU-ESP8266-WiFi-Robot-Car-Controlled-by-Appli/">car</a></li>
<li>Computer with installed with <a href="https://www.neuropype.io/#editions">NeuroPype</a></li>
<li>Computer with installed [OpenBCI GUI] (<a href="https://github.com/OpenBCI/OpenBCI_GUI/releases">https://github.com/OpenBCI/OpenBCI_GUI/releases</a>)</li>
<li>Computer with installed <a href="https://www.arduino.cc/en/software">Arduino IDE</a></li>
</ol>
<h2><a class="anchor" aria-hidden="true" id="hardware-setup"></a><a href="#hardware-setup" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Hardware Setup</h2>
<p>If you are using the assembled Ultracortex IV, all you need to do is place the spiky electrodes on the following 10-20 locations: C3 ,Cz, C4, P3, Pz, P4, O1, O2 and FPz. If you want to assemble the headset yourself follow this tutorial.
Next, connect the electrodes to the Cyton board pins as shown on the table below.</p>
<p><img src="/docs/assets/TutorialImages/Electrode_Chart.png" alt="Electrode Chart"></p>
<p><img src="/docs/assets/TutorialImages/electrode_placement.png" alt="Electrode placement for Motor Imagery"></p>
<p>You can either use the EEG Electrode Cap or the Ultracortex Mark IV headset. This demonstration uses a <a href="https://shop.openbci.com/collections/frontpage/products/openbci-eeg-electrocap">dedicated EEG cap</a>.</p>
<p><img src="/docs/assets/TutorialImages/EEG_Cap.png" alt="Using a Brain Product Easy Cap for Data Acquisition"></p>
<h1><a class="anchor" aria-hidden="true" id="software-setup"></a><a href="#software-setup" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Software Setup</h1>
<p>Let us design a two-class BCI using the software NeuroPype. NeuroPype is free for academic users and you can get a 30 day trial if you are an individual/startup. You can get started with NeuroPype by clicking <a href="https://www.neuropype.io/">here</a>.</p>
<h3><a class="anchor" aria-hidden="true" id="imagined-moments-classification"></a><a href="#imagined-moments-classification" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Imagined Moments Classification</h3>
<p>To start open the Neuropype Pipeline Designer application. Go to file and open Simple Motor Imagery Prediction with CSP. We will use the example provided by Neuropype software.</p>
<p><img src="/docs/assets/TutorialImages/Neuropype_Branch_Layout.png" alt="Branch Layout"></p>
<p>This pipeline uses EEG to predict whether you’re currently imagining one of the possible limb movements (default: left-hand movement vs. right-hand movement for two-class classification). The output of this pipeline at any tick is the probability that the person imagines each type of movement. Since the EEG patterns associated with these movements look different for any two people, several nodes (here: Common Spatial Patterns and Logistic Regression) must first adapt themselves based on some calibration data for the particular user. Moreover, it’s not enough for the calibration data to be arbitrary EEG data, it must meet certain criteria (this same rule applies to pretty much any use of machine learning on EEG data). First, the node needs to obtain examples of EEG left-hand movement and right-hand movement, respectively. Also, a single trial per class of movement is not enough,  the node needs to see close to 20–50 repeats when using a full-sized EEG headset. Lastly, these trials must be in a randomized order, i.e., not simply a block of all-left trials followed by a block of all-right trials. Collecting data in that way is one of the most common beginner mistakes with machine learning on time series, and it is important to avoid it.</p>
<h3><a class="anchor" aria-hidden="true" id="working-with-eeg-markers"></a><a href="#working-with-eeg-markers" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Working with EEG Markers</h3>
<p><img src="/docs/assets/TutorialImages/Assign_Target_Node.png" alt="Assign Targets Node"></p>
<p>For the aforementioned reasons, the EEG signal must be annotated such that one can tell which data points correspond to Class 1 (subject imagines left-hand movement) and which ones correspond to Class 2 (subject imagines right-hand movement). One way to do this is to include a special ‘trigger channel’ in the EEG, which takes on pre-defined signal levels that encode different classes (e.g. 0=left, 1=right). In that case, the pipeline assumes that the data packets emitted by the LSL Input node are not just one EEG stream, but also a second stream that has a list of marker strings along with their timestamps (markers), i.e., they are multi-stream packets and there are consequently two data streams flowing through the entire pipeline. The markers are then interpreted by the rest of the pipeline to indicate the points in time around which the EEG is of a particular class (in this pipeline, a marker with the string ‘left’ and time-stamp 17.5 would indicate that the EEG at 17.5 seconds into the recording is of class 0, and if the marker had been ‘right’ it would indicate class 1).
Of course, the data could contain any amount of other random markers (e.g., ‘recording-started’, ‘user-was-sneezing’, ‘enter-pressed’), so how does the pipeline know what markers encode classes, and which classes they encode? This binding is established by the Assign Targets node. The settings are shown below. The syntax means that ‘left’ strings map to class 0, ‘right’ maps to class 1, and all other strings don’t map to anything.</p>
<h3><a class="anchor" aria-hidden="true" id="segmentation"></a><a href="#segmentation" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Segmentation</h3>
<p><img src="/docs/assets/TutorialImages/Segmentation_Node.png" alt="Segmentation Node"></p>
<p>The second question is, given that there’s a marker at 17.5 seconds, how does the pipeline know where relative to that point in time we find the relevant pattern in the EEG that captures the imagined movement? Does it start a second before the marker and end a second after, or does it start at the marker and end 10 seconds later? Extracting the right portion of the data is usually handled by the Segmentation node, which extracts segments of a certain length relative to each marker. The picture above shows the settings for this pipeline, which are interpreted as follows: extract a segment that starts at 0.5 seconds after each marker and ends at 3.5 seconds after that marker (i.e., the segment is 3 seconds long). If you use negative numbers, you can place the segment before the marker.</p>
<h3><a class="anchor" aria-hidden="true" id="acquition-of-eeg-data-and-markers"></a><a href="#acquition-of-eeg-data-and-markers" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Acquition of EEG Data and Markers</h3>
<p>Plug in the RFduino dongle, connect electrodes to the cyton board pins. Wear the EEG headset and finally connect the ear clip to SRB. Open the OpenBCI GUI, select the appropriate port number and start streaming data from the Cyton board. Go to the networking tab and select the LSL protocol. Select “TIME-SERIES” data type and start streaming.</p>
<p><img src="/docs/assets/TutorialImages/Hardware_Setting_in_the_GUI.png" alt="Hardware setting in the GUI"></p>
<p><img src="/docs/assets/TutorialImages/The_OpenBCI_GUI.png" alt="The OpenBCI GUI"></p>
<p>Before we start classifying the Motor Imagery data, we need to calibrate the system.</p>
<h3><a class="anchor" aria-hidden="true" id="recording-calibration-data"></a><a href="#recording-calibration-data" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Recording Calibration Data</h3>
<p>The NeuroPype pipeline is doing a great job, but wouldn’t it be nice if we didn’t have to recollect the calibration data each time we run the pipeline? It’s often more convenient to record calibration data into a file in the first session, and load that file every time we run our pipeline. For this, we need to use the Inject Calibration Data node, which has a second input port where one can pipe a calibration recording (which we import here using Import XDF).
Start the Lab recorder and find the OpenBCI EEG stream in the window. Now run the python script motorimg_calibrate.py found in the extras folder in your Neuropype installation folder. Now update the streams in the lab recorder. You should now see MotorImag-Markers and obci_eeg1 stream along with your computer name.</p>
<p><img src="/docs/assets/TutorialImages/Lab_Recorder.png" alt="Lab Recorder"></p>
<p>The python script along with OpenBCI, lab recorder is used to record calibration data. The script sends markers matching what the person is imagining that is 'Left' or 'Right' and instructs the user when to imagine that movement which will be stored in the .xdf file along with the EEG data.
Run the python script and start recording the OpenBCI stream and markers stream using the lab recorder. Follow the instructions shown on the window: when the window shows ‘R’  imagine moving your right arm, and when it shows ‘L’   imagine moving your left arm.  It takes about half a second for a person to read the instruction and begin imagining the movement, and he/she will finish about 3 seconds later and get ready for the next trial. This is why the segment time limits in the segmentation node are set to (0.5,3.5).
You can configure the number of trials per class and other parameters in motorimg_calibrate.py.</p>
<h3><a class="anchor" aria-hidden="true" id="import-calibration-data"></a><a href="#import-calibration-data" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Import Calibration Data</h3>
<p>You need to edit a few nodes in this pipeline. You should delete these three nodes (Import SET, Stream Data, LSL Output) at the bottom of the pipeline design as we will use our own recorded calibration data.</p>
<p><img src="/docs/assets/TutorialImages/Calibration_Data.png" alt="Calibration Data">
Delete these nodes from the Pipeline Design</p>
<p>Delete the Import Set node that is connected to Inject Calibration Data and replace it with Import XDF as the calibration data is recorded in .xdf format.</p>
<p><img src="/docs/assets/TutorialImages/Import_XDF.png" alt="Import XDF"></p>
<p>Replace the Import Set with Import XDF</p>
<p>Enter the calibration data filename
Fill in the appropriate filename of the XDF file in the window.</p>
<h3><a class="anchor" aria-hidden="true" id="picking-up-marker-streams-with-lsl"></a><a href="#picking-up-marker-streams-with-lsl" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Picking up Marker Streams with LSL</h3>
<p><img src="/docs/assets/TutorialImages/LSL_Input.png" alt="LSL Input"></p>
<p>The LSL Input node is responsible for returning a marker stream together with the EEG. Enter the name of the OpenBCI stream in the query and after you import the .xdf calibration data, you are ready to go.</p>
<h3><a class="anchor" aria-hidden="true" id="streaming-the-data"></a><a href="#streaming-the-data" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Streaming the Data</h3>
<p><img src="/docs/assets/TutorialImages/OSC_Output.png" alt="OSC Output"></p>
<p>Connect an OSC (Open sound control) Output node to the Logistic Regression node in the pipeline designer and configure it as shown below before you stream the data.</p>
<p><img src="/docs/assets/TutorialImages/OSC_Number_Output.png" alt="OSC Number_Output"></p>
<p>OSC(Open Sound Control) output
Type in the IP address of the device to which you want to stream the data, which can be either an Arduino or a Raspberry Pi). Use 127.0.0.1 as an IP address if you want to receive the data on your local computer.
<a href="https://github.com/OpenBCI/OpenBCI_Tutorials/tree/master/Motor_Imagery">Here</a> is a python code to receive the streamed data on the local computer.</p>
<h3><a class="anchor" aria-hidden="true" id="running-neuropype-pipeline"></a><a href="#running-neuropype-pipeline" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Running NeuroPype Pipeline</h3>
<p><img src="/docs/assets/TutorialImages/Neuropype_Icon.png" alt="NeuroPype Icon"></p>
<p>We are in the final stage of the Motor Imagery Classification pipeline design. Now right click on the NeuroPype icon in the taskbar and click run pipeline. Navigate to your file path and select your edited pipeline simplemotorimagery.pyp and run it. If everything is configured properly, you will get two windows showing the Classification and Misclassification Rate. You can now see real-time predictions of either left or right on the windows. Imagine moving your right arm to increase the amplitude power of the right prediction and imagine moving your left arm to increase the amplitude power of the left prediction.</p>
<p><img src="/docs/assets/TutorialImages/Classification.png" alt="Classification Icon"></p>
<p>When you run the python script on your local computer, you should receive the prediction data as shown below.</p>
<p><img src="/docs/assets/TutorialImages/OSC_Python_output.png" alt="OSC output from python script"></p>
<p>The car above uses NodeMCU and L298N motor driver. The NodeMCU coded in <a href="https://www.arduino.cc/en/software">Arduino IDE</a> and the <a href="https://github.com/OpenBCI/OpenBCI_Tutorials/tree/master/Motor_Imagery">code</a> is mentioned below. To learn how to use NodeMCU click <a href="https://create.arduino.cc/projecthub/auggujarat/getting-started-with-nodemcu-esp8266-on-arduino-ide-b7e18e">here</a>.</p>
<p>This OSC protocol is widely used in fields like musical expression, robotics, video performance interfaces, distributed music systems, and inter-process communication. You can use it to drive motors, activate devices, and much more. This example video uses the OSC output to control the direction of rotation of the car.
Following this tutorial, you will be able to design your own Motor Imagery Classification with your own calibration data and control cars, drones, and devices.
Start using BCI technologies to bring products of your imagination to life - there is no limit to what you can imagine!</p>
</span></div></article></div><div class="docLastUpdate"><em>Last updated on 3/30/2021</em></div><div class="docs-prevnext"><a class="docs-prev button" href="/docs/07Examples/19-EEGProjects/FocusArduino"><span class="arrow-prev">← </span><span>Send Focus Data from GUI to Arduino</span></a><a class="docs-next button" href="/docs/08FAQ/FAQLanding"><span>Frequently Asked Questions</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#materials-required">Materials Required</a></li><li><a href="#hardware-setup">Hardware Setup</a><ul class="toc-headings"><li><a href="#imagined-moments-classification">Imagined Moments Classification</a></li><li><a href="#working-with-eeg-markers">Working with EEG Markers</a></li><li><a href="#segmentation">Segmentation</a></li><li><a href="#acquition-of-eeg-data-and-markers">Acquition of EEG Data and Markers</a></li><li><a href="#recording-calibration-data">Recording Calibration Data</a></li><li><a href="#import-calibration-data">Import Calibration Data</a></li><li><a href="#picking-up-marker-streams-with-lsl">Picking up Marker Streams with LSL</a></li><li><a href="#streaming-the-data">Streaming the Data</a></li><li><a href="#running-neuropype-pipeline">Running NeuroPype Pipeline</a></li></ul></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/" class="nav-home"><img src="/img/favicon_large.ico" alt="OpenBCI Documentation" width="52" height="52"/></a><div><h5>Site</h5><a href="https://openbci.com">OpenBCI Website</a><a href="https://shop.openbci.com">OpenBCI Store</a><a href="https://openbci.com/opportunities">Opportunities</a><a href="https://openbci.com/donation">Downloads</a></div><div><h5>Social</h5><a href="https://twitter.com/OpenBCI?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor">Twitter</a><a href="https://www.instagram.com/openbci/">Instagram</a><a href="https://www.facebook.com/OpenBCI/">Facebook</a><a href="https://www.linkedin.com/company/openbci/">LinkedIn</a></div><div><h5>More</h5><a href="https://github.com/OpenBCI">GitHub</a><a href="https://openbci.com/community/">Community</a><a href="https://openbci.com/forum/">Forum</a><a href="https://openbci.com/index.php/contact">Contact</a></div></section><section class="copyright">Copyright © 2021 OpenBCI</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: '19411ba246745c95db0bff87cfed97b0',
                indexName: 'openbci',
                inputSelector: '#search_input_react',
                algoliaOptions: {}
              });
            </script></body></html>